{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f33f31ad-a9ec-45c8-9375-2062ddc3f03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Importaciones base ─────────────────────────────\n",
    "import sys, pathlib\n",
    "PROJECT_ROOT = pathlib.Path().resolve().parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src import config as cfg\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4c3e00a-b019-419a-b812-2b255f256189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Precios cargados: (5120, 40)\n",
      "✅ Fechas válidas: (3894, 40)\n"
     ]
    }
   ],
   "source": [
    "df_prices = pd.read_parquet(cfg.DATA / \"raw\" / \"prices.parquet\").sort_index()\n",
    "print(\"✅ Precios cargados:\", df_prices.shape)\n",
    "\n",
    "# Eliminar fechas con demasiados NaNs\n",
    "min_valid_assets = int(df_prices.shape[1] * 0.8)\n",
    "df_filtered = df_prices.dropna(thresh=min_valid_assets)\n",
    "print(\"✅ Fechas válidas:\", df_filtered.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f905143c-e65e-4275-8ba7-b2b7af7e50e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Activos eliminados: []\n",
      "✅ Dimensión final sin huecos graves: (3894, 40)\n"
     ]
    }
   ],
   "source": [
    "# Relleno forward/backward limitado\n",
    "df_filled = df_filtered.ffill(limit=5).bfill(limit=5)\n",
    "\n",
    "# Eliminar activos con demasiados huecos (>17%)\n",
    "min_valid_rows = int(len(df_filled) * 0.83)\n",
    "df_filled = df_filled.dropna(axis=1, thresh=min_valid_rows)\n",
    "\n",
    "tickers_original = df_prices.columns.tolist()\n",
    "tickers_final    = df_filled.columns.tolist()\n",
    "tickers_dropped  = list(set(tickers_original) - set(tickers_final))\n",
    "print(\"❌ Activos eliminados:\", tickers_dropped)\n",
    "print(\"✅ Dimensión final sin huecos graves:\", df_filled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55744f29-ece7-473a-9e27-82573953faf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Escaladores guardados\n"
     ]
    }
   ],
   "source": [
    "# 2. CÁLCULO DE RETORNOS Y ESCALADO\n",
    "# ──────────────────────────────────\n",
    "df_ret = np.log(df_filled / df_filled.shift(1)).dropna()\n",
    "\n",
    "# ---- escalador de FEATURES (X) ----\n",
    "scaler_X = StandardScaler()\n",
    "df_scaled = pd.DataFrame(\n",
    "    scaler_X.fit_transform(df_ret),\n",
    "    index=df_ret.index,\n",
    "    columns=df_ret.columns\n",
    ")\n",
    "\n",
    "# ---- escalador del TARGET (y) ----\n",
    "scaler_y = StandardScaler()\n",
    "y_all = scaler_y.fit_transform(df_ret.values)          # mismo shape que df_ret\n",
    "\n",
    "# GUARDA ambos escaladores con nombres explícitos\n",
    "joblib.dump(scaler_X, cfg.MODELS / \"scaler_X_lstm.pkl\")\n",
    "joblib.dump(scaler_y, cfg.MODELS / \"scaler_y_lstm.pkl\")\n",
    "print(\"✅ Escaladores guardados\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f149c92-d010-4908-81ac-d0c16402def9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tensores generados:\n",
      "   X: (3239, 60, 40)\n",
      "   y: (3239, 40)\n",
      "   fechas: 2012-08-08 00:00:00 → 2025-06-26 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# 3. CONSTRUCCIÓN DE MUESTRAS (X, y)\n",
    "# ──────────────────────────────────\n",
    "X, y, fechas = [], [], []\n",
    "WINDOW  = cfg.WINDOW\n",
    "HORIZON = cfg.TARGET_HORIZON\n",
    "\n",
    "vals     = df_scaled.values          # ← features ya escaladas\n",
    "targets  = y_all                     # ← ✅ target **escalado**, NO df_ret\n",
    "\n",
    "for i in range(WINDOW, len(vals) - HORIZON + 1):\n",
    "    X.append(vals[i - WINDOW:i])\n",
    "    y.append(targets[i + HORIZON - 1])   # ← ahora coge la versión escalada\n",
    "    fechas.append(df_ret.index[i + HORIZON - 1])\n",
    "\n",
    "X      = np.array(X, dtype=np.float32)\n",
    "y      = np.array(y, dtype=np.float32)\n",
    "fechas = pd.to_datetime(fechas)\n",
    "\n",
    "\n",
    "print(\"✅ Tensores generados:\")\n",
    "print(\"   X:\", X.shape)\n",
    "print(\"   y:\", y.shape)\n",
    "print(\"   fechas:\", fechas.min(), \"→\", fechas.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be0dae6e-8f93-44be-a0bc-8ecdfc9ec07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Datos listos y guardados en: C:\\Users\\ferra\\Documents\\TFM\\data\\processed\\lstm_data.pkl\n"
     ]
    }
   ],
   "source": [
    "joblib.dump({\n",
    "    \"X\": X,\n",
    "    \"y\": y,\n",
    "    \"tickers\": df_ret.columns.tolist(),\n",
    "    \"dates\": fechas,\n",
    "    \"scaler_X\": scaler_X,    # ← opcional\n",
    "    \"scaler_y\": scaler_y     # ← opcional\n",
    "}, cfg.DATA / \"processed\" / \"lstm_data.pkl\")\n",
    "\n",
    "print(\"✅ Datos listos y guardados en:\", cfg.DATA / \"processed\" / \"lstm_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab16d10-4852-4d06-8af9-9a41926afe4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586875f5-8ad9-4e04-8862-799791779580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79966c01-fe90-4e1e-8e54-09af80410f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03fa49e-cc96-4365-ba52-8f065ad48157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6111d1c-09e5-4a4a-a243-aec1db9ace91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4ce7d76-df40-48e4-9cdc-46bca0e1e4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fechas válidas: (3894, 40)\n"
     ]
    }
   ],
   "source": [
    "min_valid_assets = int(df_prices.shape[1] * 0.8)\n",
    "df_filtered = df_prices.dropna(thresh=min_valid_assets)\n",
    "\n",
    "print(\"✅ Fechas válidas:\", df_filtered.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a820d290-7c5a-4080-bc1a-1196f4d7c512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Activos eliminados por huecos excesivos: []\n",
      "✅ Sin huecos graves. Dimensión final: (3894, 40)\n"
     ]
    }
   ],
   "source": [
    "# Forward-fill + back-fill en festivos\n",
    "df_filled = df_filtered.ffill(limit=5).bfill(limit=5)\n",
    "\n",
    "# Eliminar activos con muchos huecos (>17%)\n",
    "min_valid_rows = int(len(df_filled) * 0.83)\n",
    "df_filled = df_filled.dropna(axis=1, thresh=min_valid_rows)\n",
    "\n",
    "tickers_original = df_prices.columns.tolist()\n",
    "tickers_final    = df_filled.columns.tolist()\n",
    "tickers_dropped  = list(set(tickers_original) - set(tickers_final))\n",
    "\n",
    "print(\"❌ Activos eliminados por huecos excesivos:\", tickers_dropped)\n",
    "\n",
    "print(\"✅ Sin huecos graves. Dimensión final:\", df_filled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bd21d3c-0fff-496d-9112-456c6f10fea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Retornos calculados: (3299, 40)\n",
      "✅ Datos normalizados (media ≈ 0, std ≈ 1)\n"
     ]
    }
   ],
   "source": [
    "df_ret = np.log(df_filled / df_filled.shift(1)).dropna()\n",
    "print(\"✅ Retornos calculados:\", df_ret.shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(df_ret),\n",
    "    index=df_ret.index,\n",
    "    columns=df_ret.columns\n",
    ")\n",
    "\n",
    "print(\"✅ Datos normalizados (media ≈ 0, std ≈ 1)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "603a99c7-2c51-40e4-9298-4c230b6eb0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\ferra\\\\Documents\\\\TFM\\\\data\\\\processed\\\\ret_scaler.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler, cfg.DATA / \"processed\" / \"ret_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3f5e5c5-57c1-4c42-ab03-56a75c2011d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tensores generados: X: (1609, 60, 40) | y: (1609, 40)\n"
     ]
    }
   ],
   "source": [
    "# Cortar temporalmente el DataFrame hasta 2018-12-31\n",
    "df_scaled = df_scaled.loc[df_ret.index]  # mantener misma ventana\n",
    "\n",
    "X, y = [], []\n",
    "WINDOW = cfg.WINDOW\n",
    "HORIZON = cfg.TARGET_HORIZON\n",
    "\n",
    "vals = df_scaled.values\n",
    "targets = df_ret.values  # sin escalar\n",
    "\n",
    "for i in range(WINDOW, len(vals) - HORIZON + 1):\n",
    "    X.append(vals[i - WINDOW:i])\n",
    "    y.append(targets[i + HORIZON - 1])\n",
    "\n",
    "import numpy as np\n",
    "X = np.array(X, dtype=np.float32)\n",
    "y = np.array(y, dtype=np.float32)\n",
    "\n",
    "print(\"✅ Tensores generados:\", \"X:\", X.shape, \"| y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e91dfc8b-d178-46bd-9a74-9f1463a74536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Datos listos y guardados en: C:\\Users\\ferra\\Documents\\TFM\\data\\processed\\lstm_data.pkl\n"
     ]
    }
   ],
   "source": [
    "# Obtener fechas asociadas a cada muestra (último día de la ventana)\n",
    "dates = df_ret.index[WINDOW + HORIZON - 1:]\n",
    "\n",
    "# Validar longitudes\n",
    "assert len(dates) == len(X), f\"Mismatch: {len(dates)} fechas vs {len(X)} muestras\"\n",
    "\n",
    "joblib.dump({\n",
    "    \"X\": X,\n",
    "    \"y\": y,\n",
    "    \"tickers\": df_ret.columns.tolist(),\n",
    "    \"dates\": dates\n",
    "}, cfg.DATA / \"processed\" / \"lstm_data.pkl\")\n",
    "\n",
    "print(\"✅ Datos listos y guardados en:\", cfg.DATA / \"processed\" / \"lstm_data.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd237a4-a21d-47c6-8e82-3d72dec4c09c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFM (tfmm)",
   "language": "python",
   "name": "tfmm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
